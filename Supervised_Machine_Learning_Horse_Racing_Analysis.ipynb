{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Example sklearn pipeline workflow\n",
    "\n",
    "1. Create a ColumnTranformer to preprocess data\n",
    "2. Create a Pipeline to fit model\n",
    "3. Fit pipeline using GridSearchCV\n",
    "4. Save best model to file\n",
    "5. Read saved model to predict on new data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XGBoost in /Applications/anaconda3/lib/python3.8/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.8/site-packages (from XGBoost) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /Applications/anaconda3/lib/python3.8/site-packages (from XGBoost) (1.5.0)\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"!pip install XGBoost\";\n",
       "                var nbb_formatted_code = \"!pip install XGBoost\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"import pickle\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\n\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom category_encoders import LeaveOneOutEncoder\\n\\n# Replace with whatever model import(s) you're using\\nfrom sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_formatted_code = \"import pickle\\n\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\n\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom category_encoders import LeaveOneOutEncoder\\n\\n# Replace with whatever model import(s) you're using\\nfrom sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "# Replace with whatever model import(s) you're using\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out your column datatypes here\n",
    "num_cols = []\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "cat_cols = []\n",
    "drop_cats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "preprocessing = ColumnTransformer([\n",
    "    # Encode categories\n",
    "    # Potentially use one of the 2 below options\n",
    "    (\"OneHotEncoder\", OneHotEncoder(drop=drop_cats), cat_cols),\n",
    "    # ('leaveoneoutencoder', LeaveOneOutEncoder(), cat_cols),\n",
    "\n",
    "    # Scale numeric columns\n",
    "    # (not needed for all models but can't hurt)\n",
    "    (\"scaler\", StandardScaler(), num_cols)\n",
    "    # bin_cols we'll leave untouch\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # Apply ColumnTransformer steps\n",
    "    (\"preprocessing\", preprocessing),\n",
    "\n",
    "    # Add other steps as desired\n",
    "    # ('dim_reduction', PCA()),\n",
    "    # ('feature_selection', SelectKBest()),\n",
    "\n",
    "    # Choose your model and put it here\n",
    "    (\"model\", RandomForestClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"model__n_estimators\": [100, 150],\n",
    "\n",
    "    # Add other hyperparameters to tune as desired\n",
    "    # 'dim_reduction__n_components': [2, 3, 4]\n",
    "}\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv = GridSearchCV(pipeline, grid)\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train score: {pipeline_cv.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test score: {pipeline_cv.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model using additional appropriate metrics\n",
    "# If doing regression consider:\n",
    "# * Mean Absolute Error\n",
    "# * Mean Absolute Percent Error\n",
    "# * Fitted by Actuals scatter plot\n",
    "\n",
    "# If doing classification consider:\n",
    "# * Confusion matrix\n",
    "# * Classification report\n",
    "\n",
    "# Save to file\n",
    "best_model = pipeline_cv.best_estimator_\n",
    "with open(\"saved_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "\n",
    "# Load from file\n",
    "with open(\"saved_model.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "preds = loaded_model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
